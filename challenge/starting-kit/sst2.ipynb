{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membership Inference Competition (MICO) @ IEEE SatML 2023: SST-2\n",
    "\n",
    "Welcome to the MICO competition!\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to one of the challenges.\n",
    "\n",
    "Let's start by downloading and extracting the archives for the SST-2 challenge.\n",
    "We split the challenge data into three archives, one per scenario (~80GiB each).\n",
    "Downloading, verifying, and extracting them can take a while, so you may want to run the cell below only once.\n",
    "\n",
    "**NOTE**: Public anonymous access to the competition data is disabled. \n",
    "Upon registering for the competition, you will be shown URLs with embedded bearer tokens that you must use instead of the URLs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "\n",
    "files = [\n",
    "    {\n",
    "        'filename' : 'sst2_lo.tar.gz',\n",
    "        'url': 'https://membershipinference.blob.core.windows.net/mico/sst2_lo.tar.gz',\n",
    "        'md5': '205414dd0217065dcebe2d8adc1794a3'\n",
    "    },\n",
    "    {\n",
    "        'filename' : 'sst2_hi.tar.gz',\n",
    "        'url': 'https://membershipinference.blob.core.windows.net/mico/sst2_hi.tar.gz',\n",
    "        'md5': 'd285958529fcad486994347478feccd2'\n",
    "    },\n",
    "    {\n",
    "        'filename' : 'sst2_inf.tar.gz',\n",
    "        'url': 'https://membershipinference.blob.core.windows.net/mico/sst2_inf.tar.gz',\n",
    "        'md5': '7dca44b191a0055edbde5c486a8fc671'\n",
    "    }\n",
    "]\n",
    "\n",
    "# WARNING: this will download and extract three ~80GiB files, if not already present. Please save the files and avoid re-downloading them.\n",
    "try:\n",
    "    for f in files:\n",
    "        url, filename, md5 = f['url'], f['filename'], f['md5']\n",
    "        print(f\"Downloading and extracting {filename}...\")\n",
    "        download_and_extract_archive(url=url, download_root=os.curdir, extract_root=None, filename=filename, md5=md5, remove_finished=False)\n",
    "except urllib.error.HTTPError as e:\n",
    "    print(e)\n",
    "    print(\"Have you replaced the URLs above with the one you got after registering?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "The archives were extracted under the `sst2` folder containing 3 sub-folders, one for each of the scenarios in the challenge:\n",
    "\n",
    "- `sst2_lo`  : Models trained with DP-SGD and a small privacy budget ($\\epsilon \\approx 4$) \n",
    "- `sst2_hi`  : Models trained with DP-SGD and a large privacy budget ($\\epsilon \\approx 10$) \n",
    "- `sst2_inf` : Models trained without differential privacy guarantee ($\\epsilon = \\infty$)\n",
    "\n",
    "Each of these folders contains 3 other folders:\n",
    "\n",
    "- `train`: Models with metadata allowing to reconstruct their full training datasets. Use these to develop your attacks without having to train your own models.\n",
    "- `dev`: Models with metadata allowing to reconstruct just the set of challenge examples. Membership predictions for these challenges will be used to evaluate submissions during the competition and update the live scoreboard in CodaLab. \n",
    "- `final`: Models with metadata allowing to reconstruct just the set of challenge examples. Membership predictions for these challenges will be used to evaluate submissions when the competition closes and to determine the final ranking.\n",
    "\n",
    "Each model folder in `train`, `dev`, and `final` contains `pytorch_model.bin`, `config.json` files with the model weights and configuration. There are 100 models in `train`, and 50 models in each of `dev` and `final`.\n",
    "\n",
    "Models in the `train` folder come with 3 PRNG seeds used to reconstruct the set of member and non-member challenge examples, and the rest of the examples in the training dataset of the model. Additionally (and redundantly), a `solution.csv` file reveals the membership information of the challenge examples.\n",
    "\n",
    "Models in the `dev` and `final` folders contain just 1 PRNG seed used to reconstruct the set of challenge examples, without revealing which were included in the training dataset.\n",
    "\n",
    "We provide utilities to reconstruct the different data splits from provided seeds and to load models as classes inheriting from `torch.nn.Module`. If you use TensorFlow, JAX, or any other framework, you can easily convert the models to the appropriate format (e.g. using ONXX).\n",
    "\n",
    "Here's a summary of how the contents are structured:\n",
    "\n",
    "- `sst2_lo`\n",
    "  - `train`\n",
    "      - `model_0`\n",
    "        - `pytorch_model.bin`, `config.json`: Serialized model weights and configuration\n",
    "        - `seed_challenge`: PRNG seed used to select a list of 100 challenge examples\n",
    "        - `seed_training`: PRNG seed used to select the non-challenge examples in the training dataset\n",
    "        - `seed_membership`: PRNG seed used to split the set of challenge examples into members and non-members (100 of each)\n",
    "        - `solution.csv`: Membership information of the challenge examples (`1` for member, `0` for non-member)\n",
    "      - ...\n",
    "  - `dev`\n",
    "      - `model_100`\n",
    "        - `pytorch_model.bin`, `config.json`\n",
    "        - `seed_challenge`\n",
    "      - ...\n",
    "  - `final`\n",
    "    - `model_150`\n",
    "      - `pytorch_model.bin`, `config.json`\n",
    "      - `seed_challenge`\n",
    "    - ...\n",
    "- `sst2_hi`\n",
    "  - ...\n",
    "- `sst2_inf`\n",
    "  - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaLab.**\n",
    "\n",
    "In the following, we will show you how to compute predictions from a basic membership inference attack and package them as a submission archive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from mico_competition import ChallengeDataset, load_sst2, load_model\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA is not available; the below would only work with CUDA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHALLENGE = \"sst2\"\n",
    "LEN_TRAINING = 67349\n",
    "LEN_CHALLENGE = 100\n",
    "\n",
    "scenarios = os.listdir(CHALLENGE)\n",
    "phases = ['dev', 'final', 'train']\n",
    "\n",
    "dataset = load_sst2()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "for scenario in tqdm(scenarios, desc=\"scenario\"):\n",
    "    for phase in tqdm(phases, desc=\"phase\"):\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            challenge_dataset = ChallengeDataset.from_path(path, dataset=dataset, len_training=LEN_TRAINING)\n",
    "            challenge_points = challenge_dataset.get_challenges()\n",
    "\n",
    "            # This is where you plug in your membership inference attack\n",
    "            # As an example, here is a simple loss threshold attack\n",
    "\n",
    "            # Loss Threshold Attack\n",
    "            model = load_model('sst2', path)\n",
    "            challenge_dataloader = torch.utils.data.DataLoader(challenge_points, batch_size=10)\n",
    "        \n",
    "            model.to(torch.device('cuda'))\n",
    "            predictions = []\n",
    "            for batch in challenge_dataloader:\n",
    "                labels = batch['label'].to(torch.device('cuda'))\n",
    "                tokenizedSequences = tokenizer(batch['sentence'], return_tensors=\"pt\", padding=\"max_length\", max_length=67)\n",
    "                tokenizedSequences = tokenizedSequences.to(torch.device('cuda'))\n",
    "                output = model(**tokenizedSequences)\n",
    "                batch_predictions = -criterion(output.logits, labels).detach().cpu().numpy()\n",
    "                predictions.extend(batch_predictions)\n",
    "            \n",
    "            # Normalize to unit interval\n",
    "            min_prediction = np.min(predictions)\n",
    "            max_prediction = np.max(predictions)\n",
    "            predictions = (predictions - min_prediction) / (max_prediction - min_prediction)\n",
    "\n",
    "            assert np.all((0 <= predictions) & (predictions <= 1))\n",
    "\n",
    "            with open(os.path.join(path, \"prediction.csv\"), \"w\") as f:\n",
    "                 csv.writer(f).writerow(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth. \n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mico_competition.scoring import tpr_at_fpr, score, generate_roc, generate_table\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "FPR_THRESHOLD = 0.1\n",
    "\n",
    "all_scores = {}\n",
    "phases = ['train']\n",
    "\n",
    "for scenario in tqdm(scenarios, desc=\"scenario\"): \n",
    "    all_scores[scenario] = {}    \n",
    "    for phase in tqdm(phases, desc=\"phase\"):\n",
    "        predictions = []\n",
    "        solutions  = []\n",
    "\n",
    "        root = os.path.join(CHALLENGE, scenario, phase)\n",
    "        for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "            path = os.path.join(root, model_folder)\n",
    "            predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\"), delimiter=\",\"))\n",
    "            solutions.append(np.loadtxt(os.path.join(path, \"solution.csv\"),   delimiter=\",\"))\n",
    "\n",
    "        predictions = np.concatenate(predictions)\n",
    "        solutions = np.concatenate(solutions)\n",
    "        \n",
    "        scores = score(solutions, predictions)\n",
    "        all_scores[scenario][phase] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the ROC curve for the attack and see how the attack performed on different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "for scenario in scenarios:\n",
    "    fpr = all_scores[scenario]['train']['fpr']\n",
    "    tpr = all_scores[scenario]['train']['tpr']\n",
    "    fig = generate_roc(fpr, tpr)\n",
    "    fig.suptitle(f\"{scenario}\", x=-0.1, y=0.5)\n",
    "    fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    scores = all_scores[scenario]['train']\n",
    "    scores.pop('fpr', None)\n",
    "    scores.pop('tpr', None)\n",
    "    display(pd.DataFrame([scores]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "phases = ['dev', 'final']\n",
    "\n",
    "with zipfile.ZipFile(\"predictions_sst2.zip\", 'w') as zipf:\n",
    "    for scenario in tqdm(scenarios, desc=\"scenario\"): \n",
    "        for phase in tqdm(phases, desc=\"phase\"):\n",
    "            root = os.path.join(CHALLENGE, scenario, phase)\n",
    "            for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    zipf.write(file)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}. You need to provide predictions for all challenges\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mico-competition')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
